from pyspark.sql import SparkSession
from pyspark.sql.functions import udf, col, trim, length
from pyspark.sql.types import StringType, FloatType
import time
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# === Spark baÅŸlat ===
def create_spark():
    return SparkSession.builder \
        .appName("VADER_Sentiment_Analysis_Spark") \
        .master("spark://192.168.56.102:7077") \
        .config("spark.executor.memory", "4g") \
        .config("spark.driver.memory", "2g") \
        .getOrCreate()

# === NLTK VADER ayarÄ± ===
nltk.data.path.append("/home/seed/nltk_data")
try:
    nltk.data.find('sentiment/vader_lexicon')
except:
    nltk.download('vader_lexicon', download_dir="/home/seed/nltk_data")

analyzer = SentimentIntensityAnalyzer()

def get_vader_score(text):
    if not text:
        return None
    try:
        return float(analyzer.polarity_scores(text)['compound'])
    except:
        return None

def get_sentiment_label(score):
    if score is None:
        return "NÃ¶tr"
    elif score > 0.05:
        return "Pozitif"
    elif score < -0.05:
        return "Negatif"
    else:
        return "NÃ¶tr"

# === Spark baÅŸlat ===
spark = create_spark()

# === Zaman baÅŸlat ===
total_start = time.time()

# === Veri setini oku (multiline + tÄ±rnak escape destekli) ===
load_start = time.time()
df = spark.read.csv(
    "file:///home/seed/Desktop/dagitik/cleaned_twitter_data.csv",
    header=True,
    inferSchema=True,
    multiLine=True,
    quote='"',
    escape='"'
)
load_end = time.time()

print(f"âœ… Dosyadan okunan toplam satÄ±r sayÄ±sÄ±: {df.count()} satÄ±r ({load_end - load_start:.2f} saniye)")

# === Temiz metin olmayanlarÄ± Ã§Ä±kar (boÅŸluklarÄ± da hesaba kat) ===
df = df.filter((col("cleaned_text").isNotNull()) & (length(trim(col("cleaned_text"))) > 0))
print(f"âœ… GeÃ§erli temizlenmiÅŸ metin sayÄ±sÄ±: {df.count()}")

# === UDF'leri kaydet ===
vader_udf = udf(get_vader_score, FloatType())
label_udf = udf(get_sentiment_label, StringType())

# === VADER hesaplama ===
process_start = time.time()
df = df.withColumn("vader_sentiment", vader_udf(col("cleaned_text")))
df = df.withColumn("vader_category", label_udf(col("vader_sentiment")))
process_end = time.time()
print(f"âœ… Duygu hesaplama sÃ¼resi: {process_end - process_start:.2f} saniye")

# === SonuÃ§larÄ± grupla ===
analysis_start = time.time()
result = df.groupBy("vader_category").count()
result_list = result.collect()
analysis_end = time.time()

# === SonuÃ§ yaz ===
print("\nğŸ¯ Duygu analizi sonuÃ§larÄ±:")
for row in result_list:
    print(f"{row['vader_category']}: {row['count']} tweet")

# === Toplam sÃ¼re ===
total_end = time.time()
print(f"\nâ±ï¸ Toplam sÃ¼re: {total_end - total_start:.2f} saniye")

# === Kapat ===
spark.stop()
